{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716bd714",
   "metadata": {},
   "source": [
    "# Comprehensive Data Preprocessing and Analysis Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411961e8",
   "metadata": {},
   "source": [
    "## Load the Data and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b591af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/path/to/your/data/adult.data'\n",
    "column_names = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
    "    'hours_per_week', 'native_country', 'income'\n",
    "]\n",
    "data = pd.read_csv(file_path, names=column_names)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532adc9",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20860c5b",
   "metadata": {},
   "source": [
    "### Drop Redundant Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_cleaned = data.drop('education', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8883b",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_encoded = pd.get_dummies(data_cleaned, columns=[\n",
    "    'workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140370c",
   "metadata": {},
   "source": [
    "### Handle High-Cardinality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_encoded['native_country'] = data_encoded['native_country'].apply(\n",
    "    lambda x: \"Other\" if data_encoded['native_country'].value_counts()[x] < 100 else x\n",
    ")\n",
    "data_final = pd.get_dummies(data_encoded, columns=['native_country'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5ba40",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3cbac",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_matrix = data_final.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix of Numerical Features and Target\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272551c3",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c637ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_stats = data_final.describe()\n",
    "print(numerical_stats[['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff368bd",
   "metadata": {},
   "source": [
    "## Further Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040132f4",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdabd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "data_final['capital_gain_log'] = np.log(data_final['capital_gain'] + 1)\n",
    "data_final['capital_loss_log'] = np.log(data_final['capital_loss'] + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36266dd2",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_columns = ['age', 'fnlwgt', 'education_num', 'hours_per_week', 'capital_gain_log', 'capital_loss_log']\n",
    "scaler = StandardScaler()\n",
    "data_final[numerical_columns] = scaler.fit_transform(data_final[numerical_columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35283ff2",
   "metadata": {},
   "source": [
    "### Conclusion and Next Steps\n",
    "After preprocessing, scaling, and conducting an exploratory analysis, your dataset is ready for modeling. The next steps include selecting a classification model, training the model on your preprocessed dataset, and then evaluating its performance."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
